{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1ac14e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
      "Collecting torch==1.8.0+cu101\n",
      "  Using cached https://download.pytorch.org/whl/cu101/torch-1.8.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (763.5 MB)\n",
      "Collecting torchvision==0.9.0\n",
      "  Using cached https://download.pytorch.org/whl/cu101/torchvision-0.9.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (17.3 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/user/conda/lib/python3.7/site-packages (from torch==1.8.0+cu101) (4.0.1)\n",
      "Requirement already satisfied: numpy in /home/user/conda/lib/python3.7/site-packages (from torch==1.8.0+cu101) (1.21.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/user/conda/lib/python3.7/site-packages (from torchvision==0.9.0) (9.0.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0\n",
      "    Uninstalling torch-1.12.0:\n",
      "      Successfully uninstalled torch-1.12.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.0\n",
      "    Uninstalling torchvision-0.13.0:\n",
      "      Successfully uninstalled torchvision-0.13.0\n",
      "Successfully installed torch-1.8.0+cu101 torchvision-0.9.0+cu101\n"
     ]
    }
   ],
   "source": [
    "!pip install -f https://download.pytorch.org/whl/cu101/torch_stable.html torch==1.8.0+cu101 torchvision==0.9.0\n",
    "!pip install wandb==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f9102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from random import *\n",
    "seed(0)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc630c8",
   "metadata": {},
   "source": [
    "## Data trepanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd4cd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1812, 366, 365)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'barents'\n",
    "folder_train, folder_val, folder_test = dataset + '/train/maps/', dataset + '/valid/maps/', dataset + '/test/maps/'\n",
    "train_files, val_files, test_files = sorted([file for file in listdir(folder_train)])[1346:],\\\n",
    "                                     sorted([file for file in listdir(folder_val)]),\\\n",
    "                                     sorted([file for file in listdir(folder_test)]) # + 1200\n",
    "\n",
    "sample = torch.load(folder_train + train_files[1])\n",
    "grid = torch.load(dataset + \"/train/grid.pt\")\n",
    "coverage = pd.read_csv(dataset + \"/train/coverage.csv\")\n",
    "\n",
    "len(train_files), len(val_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cada2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f92e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cryosat.sic torch.Size([360, 500])\n",
      "True cryosat.sit torch.Size([360, 500])\n",
      "True jaxa.sic_asc torch.Size([360, 500])\n",
      "True jaxa.sic_desc torch.Size([360, 500])\n",
      "True jaxa.sic torch.Size([360, 500])\n",
      "False gfs.f0d.temperature torch.Size([360, 500])\n",
      "False gfs.f0d.pressure torch.Size([360, 500])\n",
      "False gfs.f0d.wind_u torch.Size([360, 500])\n",
      "False gfs.f0d.wind_v torch.Size([360, 500])\n",
      "False gfs.f0d.wind torch.Size([360, 500])\n",
      "False gfs.f1d.temperature torch.Size([360, 500])\n",
      "False gfs.f1d.pressure torch.Size([360, 500])\n",
      "False gfs.f1d.wind_u torch.Size([360, 500])\n",
      "False gfs.f1d.wind_v torch.Size([360, 500])\n",
      "False gfs.f1d.wind torch.Size([360, 500])\n",
      "False gfs.f2d.temperature torch.Size([360, 500])\n",
      "False gfs.f2d.pressure torch.Size([360, 500])\n",
      "False gfs.f2d.wind_u torch.Size([360, 500])\n",
      "False gfs.f2d.wind_v torch.Size([360, 500])\n",
      "False gfs.f2d.wind torch.Size([360, 500])\n",
      "False gfs.f3d.temperature torch.Size([360, 500])\n",
      "False gfs.f3d.pressure torch.Size([360, 500])\n",
      "False gfs.f3d.wind_u torch.Size([360, 500])\n",
      "False gfs.f3d.wind_v torch.Size([360, 500])\n",
      "False gfs.f3d.wind torch.Size([360, 500])\n"
     ]
    }
   ],
   "source": [
    "def nan_check(tensor: torch.Tensor) -> bool:\n",
    "    return True in tensor.isnan()\n",
    "\n",
    "for key in keys:\n",
    "    print(nan_check(sample[key]), key, sample[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9c36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    return (torch.nan_to_num(tensor, nan=-10.0) + grid['land']*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a253d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:03<00:00, 106.66it/s]\n",
      " 35%|███▌      | 638/1812 [00:04<00:08, 136.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm\n",
      "Alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1034/1812 [00:07<00:06, 119.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1071/1812 [00:08<00:06, 117.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1812/1812 [00:14<00:00, 128.46it/s]\n",
      "100%|██████████| 366/366 [00:02<00:00, 144.32it/s]\n"
     ]
    }
   ],
   "source": [
    "gfs_keys = [item for item in sample.keys() if ('wind' in item and 'wind_' not in item) or 'temp' in item]\n",
    "\n",
    "def handler(data: dict):\n",
    "    try:\n",
    "        return data[\"jaxa.sic\"]\n",
    "    except:\n",
    "        return data[\"jaxa.sic_asc\"]\n",
    "    \n",
    "def preprocess_image_gfs(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    layers = []\n",
    "    \n",
    "    for i in range(len(gfs_keys)):\n",
    "        if gfs_keys[i] not in tensor.keys():\n",
    "            tk = tensor.keys()\n",
    "            print(\"Alarm\")\n",
    "            for key in tk:\n",
    "                if key[-3:] == gfs_keys[i][-3:]:\n",
    "                    layers.append(tensor[key])\n",
    "                    break\n",
    "        else:\n",
    "            layers.append(tensor[gfs_keys[i]])\n",
    "            \n",
    "    sic_processed = torch.nan_to_num(handler(tensor), nan=-10.0) + grid['land']*10\n",
    "    layers.append(sic_processed)\n",
    "    \n",
    "    return torch.stack(layers)\n",
    "    \n",
    "images_test_gfs = [preprocess_image_gfs(torch.load(folder_test + test_files[i]))\\\n",
    "                            for i in tqdm(range(0, len(test_files)))]\n",
    "\n",
    "images_train_gfs = [preprocess_image_gfs(torch.load(folder_train + train_files[i]))\\\n",
    "                            for i in tqdm(range(0, len(train_files)))]\n",
    "\n",
    "images_val_gfs = [preprocess_image_gfs(torch.load(folder_val + val_files[i]))\\\n",
    "                            for i in tqdm(range(0, len(val_files)))]\n",
    "\n",
    "def average(data: list) -> float:\n",
    "    return sum(data)/len(data)\n",
    "\n",
    "def load_data_gfs(batch_size, images_tensor, d_in, d_out):\n",
    "    in_batch, out_batch = [], []\n",
    "    for i in range(batch_size):\n",
    "        start_point = choice(range(len(images_tensor) - d_in - d_out))\n",
    "        sic = images_tensor[start_point:start_point+d_in][:, -1, :, :]\n",
    "        weather = images_tensor[start_point+d_in][:-1, :, :]\n",
    "        in_batch.append(torch.cat((sic, weather), dim=0))\n",
    "        out_batch.append(images_tensor[start_point+d_in:start_point+d_in+d_out][:, -1, :, :])\n",
    "    return torch.stack(in_batch), torch.stack(out_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec301699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gfs(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step, normalize):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) #weight_decay=1e-8, momentum=0.9\n",
    "#    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "#    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    for epoch in range(1, epochs+1):\n",
    "#        print(\"Current epoch\", epoch)\n",
    "        model.train()\n",
    "        images_in, images_out = load_data_gfs(batch_size, images_tensor_train_gfs, d_in, d_out)\n",
    "        optimizer.zero_grad()\n",
    "        model_out = model(images_in[:, :, None, :, :])\n",
    "        loss = criterion(model_out[1][0], images_out)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch % eval_step == 0:\n",
    "            mae_total, rmse_total, mape_total = [], [], []\n",
    "            \n",
    "            total_test_len = len(images_tensor_test_gfs)\n",
    "            start_point, steps = 0, int(total_test_len/(d_in + d_out))\n",
    "            \n",
    "            for i in range(steps):\n",
    "                sic = images_tensor_test_gfs[start_point:start_point+d_in][:, -1, :, :]\n",
    "                weather = images_tensor_test_gfs[start_point+d_in][:-1, :, :]\n",
    "                images_in = torch.cat((sic, weather), dim=0)\n",
    "                \n",
    "                images_out = images_tensor_test_gfs[start_point+d_in:start_point+d_in+d_out][:, -1, :, :]\n",
    "                \n",
    "                start_point += d_in + d_out\n",
    "            \n",
    "                model_out = model(images_in[None, :, None, :, :])\n",
    "                \n",
    "                criterion_mse = nn.MSELoss()\n",
    "                \n",
    "                loss_mse = criterion_mse(model_out[1][0], images_out[None, :, :, :])\n",
    "                loss_mae = criterion(model_out[1][0], images_out[None, :, :, :])\n",
    "                \n",
    "                mae_total.append(loss_mae.detach().cpu().numpy())\n",
    "                rmse_total.append(math.sqrt(loss_mse.detach().cpu().numpy()))\n",
    "                \n",
    "            \n",
    "            wandb.log(\n",
    "                {\n",
    "                 \"test/test_MAE\": average(mae_total), \n",
    "                 \"test/test_RMSE\": average(rmse_total)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print('Epoch ', epoch, ', test MAE - ', average(mae_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5d32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tensor_train_gfs, images_tensor_val_gfs, images_tensor_test_gfs = torch.stack(images_train_gfs).to(device),\\\n",
    "                                                             torch.stack(images_val_gfs).to(device),\\\n",
    "                                                             torch.stack(images_test_gfs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74bef61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbercv\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-07-26 15:27:50.605507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vocal-sun-66</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction/runs/47751187\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction/runs/47751187</a><br/>\n",
       "                Run data is saved locally in <code>/home/jovyan/Ice/wandb/run-20220726_152747-47751187</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = \"ConvNet_GFS_7:3\"\n",
    "i = 0\n",
    "wandb.init(project=\"SeaIcePrediction\", entity=\"eighonet\", group=architecture)\n",
    "wandb.run.name = architecture + \"_\" + str(i)  # \"gs_3_ffd_3_128_test_MAEloss_lr_10^{-4}_10000\"\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5549d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.convlstm.convlstm import ConvLSTM\n",
    "\n",
    "epochs = 1000\n",
    "d_in, d_out = 7, 3\n",
    "batch_size = 1\n",
    "lr = 1e-2\n",
    "eval_step = 20\n",
    "criterion = nn.L1Loss()\n",
    "model_a = ConvLSTM(input_dim=1,\n",
    "                 hidden_dim=[32, 32, 32],\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=3,\n",
    "                 batch_first=True,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False,\n",
    "                 final_layer=True,\n",
    "                 num_days=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "668e5f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47 -33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf082f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.zeros(2, 7, 15, 360, 500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451dd837",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 33, 3, 3], expected input[2, 47, 360, 500] to have 33 channels, but got 47 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9326/2808581920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/convlstm/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n\u001b[0;32m--> 162\u001b[0;31m                                                  cur_state=[h, c])\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0moutput_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/convlstm/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_cur\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# concatenate along channel axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mcombined_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mcc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 33, 3, 3], expected input[2, 47, 360, 500] to have 33 channels, but got 47 channels instead"
     ]
    }
   ],
   "source": [
    "model_a(input_data)[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4420a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 31.72 GiB total capacity; 29.77 GiB already allocated; 8.44 MiB free; 30.39 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9326/865256483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"False\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9326/3065757757.py\u001b[0m in \u001b[0;36mtrain_gfs\u001b[0;34m(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step, normalize)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimages_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_gfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_tensor_train_gfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/convlstm/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n\u001b[0;32m--> 162\u001b[0;31m                                                  cur_state=[h, c])\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0moutput_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/convlstm/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mc_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_cur\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mh_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 31.72 GiB total capacity; 29.77 GiB already allocated; 8.44 MiB free; 30.39 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train_gfs(model_a, criterion, d_in, d_out, epochs, batch_size, lr, eval_step, \"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb81fe7",
   "metadata": {},
   "source": [
    "## Model trepanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcee3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 259/1812 [00:04<00:28, 55.20it/s]ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_9041/2069040888.py\", line 2, in <module>\n",
      "    for i in tqdm(range(0, len(train_files)))]\n",
      "  File \"/tmp/ipykernel_9041/2069040888.py\", line 2, in <listcomp>\n",
      "    for i in tqdm(range(0, len(train_files)))]\n",
      "  File \"/home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\", line 579, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/user/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/user/conda/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/user/conda/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/user/conda/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/user/conda/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/user/conda/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/user/conda/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9041/2069040888.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m images_train = [preprocess_image(torch.load(folder_train + train_files[i])[\"jaxa.sic\"])\\\n\u001b[0;32m----> 2\u001b[0;31m                             for i in tqdm(range(0, len(train_files)))]\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9041/2069040888.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m images_train = [preprocess_image(torch.load(folder_train + train_files[i])[\"jaxa.sic\"])\\\n\u001b[0;32m----> 2\u001b[0;31m                             for i in tqdm(range(0, len(train_files)))]\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2076\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2078\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2080\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "images_train = [preprocess_image(torch.load(folder_train + train_files[i])[\"jaxa.sic\"])\\\n",
    "                            for i in tqdm(range(0, len(train_files)))]\n",
    "\n",
    "images_val = [preprocess_image(torch.load(folder_val + val_files[i])[\"jaxa.sic\"])\\\n",
    "                            for i in tqdm(range(0, len(val_files)))]\n",
    "\n",
    "def handler(data: dict):\n",
    "    try:\n",
    "        return data[\"jaxa.sic\"]\n",
    "    except:\n",
    "        return data[\"jaxa.sic_asc\"]\n",
    "    \n",
    "images_test = [preprocess_image(handler(torch.load(folder_test + test_files[i])))\\\n",
    "                            for i in tqdm(range(0, len(test_files)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ec0322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1812, 360, 500])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tensor_train, images_tensor_val, images_tensor_test = torch.stack(images_train).to(device),\\\n",
    "                                                             torch.stack(images_val).to(device),\\\n",
    "                                                             torch.stack(images_test).to(device)\n",
    "images_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d16c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.convlstm.convlstm import ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a245886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data: list) -> float:\n",
    "    return sum(data)/len(data)\n",
    "\n",
    "def load_data(batch_size, images_tensor, d_in, d_out):\n",
    "    in_batch, out_batch = [], []\n",
    "    for i in range(batch_size):\n",
    "        start_point = choice(range(len(images_tensor) - d_in - d_out))\n",
    "        in_batch.append(images_tensor[start_point:start_point+d_in])\n",
    "        out_batch.append(images_tensor[start_point+d_in:start_point+d_in+d_out])\n",
    "    return torch.stack(in_batch), torch.stack(out_batch)\n",
    "\n",
    "def train(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) #weight_decay=1e-8, momentum=0.9\n",
    "#    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "#    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    for epoch in range(1, epochs+1):\n",
    "#        print(\"Current epoch\", epoch)\n",
    "        model.train()\n",
    "        images_in, images_out = load_data(batch_size, images_tensor_train, d_in, d_out)\n",
    "        optimizer.zero_grad()\n",
    "        model_out = model(images_in[:, :, None, :, :])\n",
    "        loss = criterion(model_out[1][0], images_out)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch % eval_step == 0:\n",
    "            mae_total, rmse_total, mape_total = [], [], []\n",
    "            \n",
    "            total_test_len = len(images_tensor_test)\n",
    "            start_point, steps = 0, int(total_test_len/(d_in + d_out))\n",
    "            \n",
    "            for i in range(steps):\n",
    "                images_in, images_out = images_tensor_test[start_point:start_point+d_in],\\\n",
    "                                        images_tensor_test[start_point+d_in:start_point+d_in+d_out]\n",
    "                \n",
    "                start_point += d_in + d_out\n",
    "            \n",
    "                model_out = model(images_in[None, :, None, :, :])\n",
    "                \n",
    "                criterion_mse = nn.MSELoss()\n",
    "                \n",
    "                loss_mse = criterion_mse(model_out[1][0], images_out[None, :, :, :])\n",
    "                loss_mae = criterion(model_out[1][0], images_out[None, :, :, :])\n",
    "                \n",
    "                mae_total.append(loss_mae.detach().cpu().numpy())\n",
    "                rmse_total.append(math.sqrt(loss_mse.detach().cpu().numpy()))\n",
    "                \n",
    "            \n",
    "            wandb.log(\n",
    "                {\n",
    "                 \"test/test_MAE\": average(mae_total), \n",
    "                 \"test/test_RMSE\": average(rmse_total)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print('Epoch ', epoch, ', test MAE - ', average(mae_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebac3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbercv\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-07-26 14:00:39.596283: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eager-morning-52</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction/runs/1qxzi059\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction/runs/1qxzi059</a><br/>\n",
       "                Run data is saved locally in <code>/home/jovyan/Ice/wandb/run-20220726_140036-1qxzi059</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = \"LSTMConv_7:10\"\n",
    "i = 0\n",
    "wandb.init(project=\"SeaIcePrediction\", entity=\"eighonet\", group=architecture)\n",
    "wandb.run.name = architecture + \"_\" + str(i)  # \"gs_3_ffd_3_128_test_MAEloss_lr_10^{-4}_10000\"\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b833d053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 , test MAE -  9.299148559570312\n",
      "Epoch  40 , test MAE -  5.907796223958333\n",
      "Epoch  60 , test MAE -  4.075190952845982\n",
      "Epoch  80 , test MAE -  3.458926972888765\n",
      "Epoch  100 , test MAE -  3.531194051106771\n",
      "Epoch  120 , test MAE -  3.486724853515625\n",
      "Epoch  140 , test MAE -  3.390653337751116\n",
      "Epoch  160 , test MAE -  3.267154511951265\n",
      "Epoch  180 , test MAE -  3.3437917800176713\n",
      "Epoch  200 , test MAE -  3.2690702165876115\n",
      "Epoch  220 , test MAE -  3.1048551286969865\n",
      "Epoch  240 , test MAE -  3.27815428234282\n",
      "Epoch  260 , test MAE -  3.2051823933919272\n",
      "Epoch  280 , test MAE -  3.715432666596912\n",
      "Epoch  300 , test MAE -  3.2678389776320684\n",
      "Epoch  320 , test MAE -  2.859410603841146\n",
      "Epoch  340 , test MAE -  2.9050599961053756\n",
      "Epoch  360 , test MAE -  2.856763930547805\n",
      "Epoch  380 , test MAE -  2.961596352713449\n",
      "Epoch  400 , test MAE -  2.940976824079241\n",
      "Epoch  420 , test MAE -  2.9703521728515625\n",
      "Epoch  440 , test MAE -  2.8600253150576638\n",
      "Epoch  460 , test MAE -  2.8381073361351374\n",
      "Epoch  480 , test MAE -  2.886488051641555\n",
      "Epoch  500 , test MAE -  3.0150833129882812\n",
      "Epoch  520 , test MAE -  2.917240869431269\n",
      "Epoch  540 , test MAE -  2.996770222981771\n",
      "Epoch  560 , test MAE -  2.8302239917573475\n",
      "Epoch  580 , test MAE -  2.8668492635091147\n",
      "Epoch  600 , test MAE -  2.923446473621187\n",
      "Epoch  620 , test MAE -  2.931900206066313\n",
      "Epoch  640 , test MAE -  2.7877684093656994\n",
      "Epoch  660 , test MAE -  2.942565373011998\n",
      "Epoch  680 , test MAE -  3.041151137579055\n",
      "Epoch  700 , test MAE -  2.791120075044178\n",
      "Epoch  720 , test MAE -  2.897676740373884\n",
      "Epoch  740 , test MAE -  2.850132533482143\n",
      "Epoch  760 , test MAE -  2.7925729297456288\n",
      "Epoch  780 , test MAE -  2.761134011404855\n",
      "Epoch  800 , test MAE -  2.7795213971819197\n",
      "Epoch  820 , test MAE -  2.895928519112723\n",
      "Epoch  840 , test MAE -  2.7638865879603793\n",
      "Epoch  860 , test MAE -  2.7420601617722284\n",
      "Epoch  880 , test MAE -  2.8591210501534596\n",
      "Epoch  900 , test MAE -  2.8587784540085566\n",
      "Epoch  920 , test MAE -  2.7401955014183406\n",
      "Epoch  940 , test MAE -  2.7710992722284224\n",
      "Epoch  960 , test MAE -  2.7851438976469494\n",
      "Epoch  980 , test MAE -  2.7413168407621837\n",
      "Epoch  1000 , test MAE -  2.748463585263207\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "d_in, d_out = 7, 10\n",
    "batch_size = 2\n",
    "lr = 1e-2\n",
    "eval_step = 20\n",
    "criterion = nn.L1Loss()\n",
    "model_a = ConvLSTM(input_dim=1,\n",
    "                 hidden_dim=[32, 32, 32],\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=3,\n",
    "                 batch_first=True,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False,\n",
    "                 final_layer=True,\n",
    "                 num_days=10).to(device)\n",
    "\n",
    "train(model_a, criterion, d_in, d_out, epochs, batch_size, lr, eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d93d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 , test MAE -  2.7056739443824407\n",
      "Epoch  40 , test MAE -  2.683204832531157\n",
      "Epoch  60 , test MAE -  2.6731089637393044\n",
      "Epoch  80 , test MAE -  2.669137500581287\n",
      "Epoch  100 , test MAE -  2.6592276436941966\n",
      "Epoch  120 , test MAE -  2.6481830051967075\n",
      "Epoch  140 , test MAE -  2.64355959211077\n",
      "Epoch  160 , test MAE -  2.6396611531575522\n",
      "Epoch  180 , test MAE -  2.649632771809896\n",
      "Epoch  200 , test MAE -  2.641253698439825\n",
      "Epoch  220 , test MAE -  2.621009281703404\n",
      "Epoch  240 , test MAE -  2.656551724388486\n",
      "Epoch  260 , test MAE -  2.662096477690197\n",
      "Epoch  280 , test MAE -  2.650421142578125\n",
      "Epoch  300 , test MAE -  2.6257945469447543\n",
      "Epoch  320 , test MAE -  2.6294987996419272\n",
      "Epoch  340 , test MAE -  2.6449993678501675\n",
      "Epoch  360 , test MAE -  2.610768817719959\n",
      "Epoch  380 , test MAE -  2.6061072576613653\n",
      "Epoch  400 , test MAE -  2.663219996861049\n",
      "Epoch  420 , test MAE -  2.628437042236328\n",
      "Epoch  440 , test MAE -  2.6122064136323475\n",
      "Epoch  460 , test MAE -  2.6047920953659784\n",
      "Epoch  480 , test MAE -  2.614947182791574\n",
      "Epoch  500 , test MAE -  2.6086600167410716\n",
      "Epoch  520 , test MAE -  2.6192630586170016\n",
      "Epoch  540 , test MAE -  2.618826366606213\n",
      "Epoch  560 , test MAE -  2.5978335425967263\n",
      "Epoch  580 , test MAE -  2.5928431919642856\n",
      "Epoch  600 , test MAE -  2.5899950663248696\n",
      "Epoch  620 , test MAE -  2.5855249677385603\n",
      "Epoch  640 , test MAE -  2.5886651901971724\n",
      "Epoch  660 , test MAE -  2.5733971368698847\n",
      "Epoch  680 , test MAE -  2.5853402273995534\n",
      "Epoch  700 , test MAE -  2.5797393435523626\n",
      "Epoch  720 , test MAE -  2.577045440673828\n",
      "Epoch  740 , test MAE -  2.576795123872303\n",
      "Epoch  760 , test MAE -  2.562004634312221\n",
      "Epoch  780 , test MAE -  2.5605167207263766\n",
      "Epoch  800 , test MAE -  2.5703032357352122\n",
      "Epoch  820 , test MAE -  2.575011480422247\n",
      "Epoch  840 , test MAE -  2.553654988606771\n",
      "Epoch  860 , test MAE -  2.570512499128069\n",
      "Epoch  880 , test MAE -  2.5597679501488093\n",
      "Epoch  900 , test MAE -  2.5645675659179688\n",
      "Epoch  920 , test MAE -  2.5620845613025485\n",
      "Epoch  940 , test MAE -  2.5450797308058966\n",
      "Epoch  960 , test MAE -  2.5530117579868863\n",
      "Epoch  980 , test MAE -  2.547950926281157\n",
      "Epoch  1000 , test MAE -  2.5466475713820684\n"
     ]
    }
   ],
   "source": [
    "train(model_a, criterion, d_in, d_out, epochs, batch_size, 1e-3, eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555f948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974dfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f4204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afadb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd75aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddee00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00fdf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4cb8539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jovyan/Ice/models/convlstm/convlstm.py\u001b[0m(140)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m        \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m        \u001b[0;31m# Implement stateful ConvLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> images_in.shape\n",
      "*** NameError: name 'images_in' is not defined\n",
      "ipdb> input_tensor.shape\n",
      "torch.Size([8, 7, 360, 500])\n",
      "ipdb> input_tensor[:, :, None, :, :].shape\n",
      "torch.Size([8, 7, 1, 360, 500])\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbcc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c0860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83853ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2f400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c071aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.zeros(2, 7, 1, 360, 500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82e5c18",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 352.00 MiB (GPU 0; 31.72 GiB total capacity; 28.99 GiB already allocated; 144.44 MiB free; 30.26 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6051/3620750302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/convlstm/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n\u001b[0;32m--> 162\u001b[0;31m                                                  cur_state=[h, c])\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0moutput_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/convlstm/convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_cur\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# concatenate along channel axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mcombined_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mcc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_conv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 352.00 MiB (GPU 0; 31.72 GiB total capacity; 28.99 GiB already allocated; 144.44 MiB free; 30.26 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model_output = model_a(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d68b9335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "772cee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 3, 360, 500])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5732bd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 360, 500])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf9baea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(128, 3, kernel_size=(3, 3), padding=(1, 1), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4cbf311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 260, 500])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1(model_output[1][0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43c35544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTMCell(\n",
       "  (conv): Conv2d(65, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cell_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7855f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f9cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e93d37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3do8nt4k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3do8nt4k). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-07-24 15:10:14.801175: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rosy-sun-20</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction/runs/fcmqmx53\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction/runs/fcmqmx53</a><br/>\n",
       "                Run data is saved locally in <code>/home/jovyan/Ice/wandb/run-20220724_151010-fcmqmx53</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = \"UNet_default\"\n",
    "i = 0\n",
    "wandb.init(project=\"SeaIcePrediction\", entity=\"eighonet\", group=architecture)\n",
    "wandb.run.name = architecture + \"_\" + str(i)  # \"gs_3_ffd_3_128_test_MAEloss_lr_10^{-4}_10000\"\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "034a1989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 , test MAE -  12.035553826226128\n",
      "Epoch  40 , test MAE -  11.641056484646267\n",
      "Epoch  60 , test MAE -  11.30771213107639\n",
      "Epoch  80 , test MAE -  11.037241617838541\n",
      "Epoch  100 , test MAE -  10.864744398328993\n",
      "Epoch  120 , test MAE -  10.708236694335938\n",
      "Epoch  140 , test MAE -  10.546531677246094\n",
      "Epoch  160 , test MAE -  10.378957960340712\n",
      "Epoch  180 , test MAE -  10.214975992838541\n",
      "Epoch  200 , test MAE -  10.031992594401041\n",
      "Epoch  220 , test MAE -  9.869924757215712\n",
      "Epoch  240 , test MAE -  9.698144700792101\n",
      "Epoch  260 , test MAE -  9.531196594238281\n",
      "Epoch  280 , test MAE -  9.329873826768663\n",
      "Epoch  300 , test MAE -  9.15167490641276\n",
      "Epoch  320 , test MAE -  8.956125895182291\n",
      "Epoch  340 , test MAE -  8.773064507378471\n",
      "Epoch  360 , test MAE -  8.569566514756945\n",
      "Epoch  380 , test MAE -  8.382956610785591\n",
      "Epoch  400 , test MAE -  8.162799411349827\n",
      "Epoch  420 , test MAE -  7.9627634684244795\n",
      "Epoch  440 , test MAE -  7.747506883409288\n",
      "Epoch  460 , test MAE -  7.530576917860243\n",
      "Epoch  480 , test MAE -  7.3310046725802955\n",
      "Epoch  500 , test MAE -  7.132966783311632\n",
      "Epoch  520 , test MAE -  6.9541371663411455\n",
      "Epoch  540 , test MAE -  6.774692111545139\n",
      "Epoch  560 , test MAE -  6.620060390896267\n",
      "Epoch  580 , test MAE -  6.482095506456163\n",
      "Epoch  600 , test MAE -  6.333454132080078\n",
      "Epoch  620 , test MAE -  6.205336252848308\n",
      "Epoch  640 , test MAE -  6.108857048882379\n",
      "Epoch  660 , test MAE -  6.038904401991102\n",
      "Epoch  680 , test MAE -  6.089605967203776\n",
      "Epoch  700 , test MAE -  5.899627685546875\n",
      "Epoch  720 , test MAE -  5.908809238009983\n",
      "Epoch  740 , test MAE -  5.8163867526584205\n",
      "Epoch  760 , test MAE -  5.81697252061632\n",
      "Epoch  780 , test MAE -  5.781601799858941\n",
      "Epoch  800 , test MAE -  5.765813615587023\n",
      "Epoch  820 , test MAE -  5.771704355875651\n",
      "Epoch  840 , test MAE -  5.681991153293186\n",
      "Epoch  860 , test MAE -  5.670168558756511\n",
      "Epoch  880 , test MAE -  5.669370863172743\n",
      "Epoch  900 , test MAE -  5.637486351860894\n",
      "Epoch  920 , test MAE -  5.614859686957465\n",
      "Epoch  940 , test MAE -  5.588077545166016\n",
      "Epoch  960 , test MAE -  5.585985819498698\n",
      "Epoch  980 , test MAE -  5.548424190945095\n",
      "Epoch  1000 , test MAE -  5.501236385769314\n"
     ]
    }
   ],
   "source": [
    "from models.unet.unet.unet_model import UNet\n",
    "\n",
    "epochs = 1000\n",
    "d_in, d_out = 7, 3\n",
    "batch_size = 8\n",
    "lr = 1e-3\n",
    "eval_step = 20\n",
    "criterion = nn.L1Loss()\n",
    "model_a = UNet(7, 3).to(device)\n",
    "\n",
    "train(model_a, criterion, d_in, d_out, epochs, batch_size, lr, eval_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2edacc",
   "metadata": {},
   "source": [
    "## UNet GFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa64da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gfs.f0d.temperature',\n",
       " 'gfs.f0d.wind',\n",
       " 'gfs.f1d.temperature',\n",
       " 'gfs.f1d.wind',\n",
       " 'gfs.f2d.temperature',\n",
       " 'gfs.f2d.wind',\n",
       " 'gfs.f3d.temperature',\n",
       " 'gfs.f3d.wind']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfs_keys = [item for item in sample.keys() if ('wind' in item and 'wind_' not in item) or 'temp' in item]\n",
    "gfs_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2498c18d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:03<00:00, 110.44it/s]\n",
      " 35%|███▌      | 639/1812 [00:05<00:11, 103.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm\n",
      "Alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1029/1812 [00:09<00:07, 98.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1059/1812 [00:10<00:07, 94.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alarm\n",
      "Alarm\n",
      "Alarm\n",
      "Alarm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1812/1812 [00:18<00:00, 99.99it/s] \n",
      "100%|██████████| 366/366 [00:03<00:00, 93.70it/s] \n"
     ]
    }
   ],
   "source": [
    "def handler(data: dict):\n",
    "    try:\n",
    "        return data[\"jaxa.sic\"]\n",
    "    except:\n",
    "        return data[\"jaxa.sic_asc\"]\n",
    "    \n",
    "def preprocess_image_gfs(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    layers = []\n",
    "    \n",
    "    for i in range(len(gfs_keys)):\n",
    "        if gfs_keys[i] not in tensor.keys():\n",
    "            tk = tensor.keys()\n",
    "            print(\"Alarm\")\n",
    "            for key in tk:\n",
    "                if key[-3:] == gfs_keys[i][-3:]:\n",
    "                    layers.append(tensor[key])\n",
    "                    break\n",
    "        else:\n",
    "            layers.append(tensor[gfs_keys[i]])\n",
    "            \n",
    "    sic_processed = torch.nan_to_num(handler(tensor), nan=-10.0) + grid['land']*10\n",
    "    layers.append(sic_processed)\n",
    "    \n",
    "    return torch.stack(layers)\n",
    "    \n",
    "images_test_gfs = [preprocess_image_gfs(torch.load(folder_test + test_files[i]))\\\n",
    "                            for i in tqdm(range(0, len(test_files)))]\n",
    "\n",
    "images_train_gfs = [preprocess_image_gfs(torch.load(folder_train + train_files[i]))\\\n",
    "                            for i in tqdm(range(0, len(train_files)))]\n",
    "\n",
    "images_val_gfs = [preprocess_image_gfs(torch.load(folder_val + val_files[i]))\\\n",
    "                            for i in tqdm(range(0, len(val_files)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2045c99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1812, 9, 360, 500])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tensor_train_gfs, images_tensor_val_gfs, images_tensor_test_gfs = torch.stack(images_train_gfs).to(device),\\\n",
    "                                                             torch.stack(images_val_gfs).to(device),\\\n",
    "                                                             torch.stack(images_test_gfs).to(device)\n",
    "images_tensor_train_gfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf6146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images_tensor_train_gfs):\n",
    "    data = images_tensor_train_gfs.cpu().numpy()\n",
    "    data_min = np.min(data, axis=(1,2,3), keepdims=True)\n",
    "    data_max = np.max(data, axis=(1,2,3), keepdims=True)\n",
    "\n",
    "    scaled_data = (data - data_min) / (data_max - data_min)\n",
    "    return torch.Tensor(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tensor_train_gfs, images_tensor_val_gfs, images_tensor_test_gfs = normalize(images_tensor_train_gfs).to(device),\\\n",
    "normalize(images_tensor_val_gfs).to(device),\\\n",
    "normalize(images_tensor_test_gfs).to(device),\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5af33da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = \"UNet_GFS_norm\"\n",
    "i = 0\n",
    "wandb.init(project=\"SeaIcePrediction\", entity=\"eighonet\", group=architecture)\n",
    "wandb.run.name = architecture + \"_\" + str(i)  # \"gs_3_ffd_3_128_test_MAEloss_lr_10^{-4}_10000\"\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data: list) -> float:\n",
    "    return sum(data)/len(data)\n",
    "\n",
    "def load_data_gfs(batch_size, images_tensor, d_in, d_out):\n",
    "    in_batch, out_batch = [], []\n",
    "    for i in range(batch_size):\n",
    "        start_point = choice(range(len(images_tensor) - d_in - d_out))\n",
    "        sic = images_tensor[start_point:start_point+d_in][:, -1, :, :]\n",
    "        weather = images_tensor[start_point+d_in][:-1, :, :]\n",
    "        in_batch.append(torch.cat((sic, weather), dim=0))\n",
    "        out_batch.append(images_tensor[start_point+d_in:start_point+d_in+d_out][:, -1, :, :])\n",
    "    return torch.stack(in_batch), torch.stack(out_batch)\n",
    "\n",
    "def train_gfs(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step, normalize):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) #weight_decay=1e-8, momentum=0.9\n",
    "#    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "#    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    for epoch in range(1, epochs+1):\n",
    "#        print(\"Current epoch\", epoch)\n",
    "        model.train()\n",
    "        images_in, images_out = load_data_gfs(batch_size, images_tensor_train_gfs, d_in, d_out)\n",
    "        optimizer.zero_grad()\n",
    "        model_out = model(images_in)\n",
    "        loss = criterion(model_out, images_out)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch % eval_step == 0:\n",
    "            mae_total, rmse_total, mape_total = [], [], []\n",
    "            \n",
    "            total_test_len = len(images_tensor_test_gfs)\n",
    "            start_point, steps = 0, int(total_test_len/(d_in + d_out))\n",
    "            \n",
    "            for i in range(steps):\n",
    "                sic = images_tensor_test_gfs[start_point:start_point+d_in][:, -1, :, :]\n",
    "                weather = images_tensor_test_gfs[start_point+d_in][:-1, :, :]\n",
    "                images_in = torch.cat((sic, weather), dim=0)\n",
    "                \n",
    "                images_out = images_tensor_test_gfs[start_point+d_in:start_point+d_in+d_out][:, -1, :, :]\n",
    "                \n",
    "                start_point += d_in + d_out\n",
    "            \n",
    "                model_out = model(images_in[None, :, :, :])\n",
    "                \n",
    "                criterion_mse = nn.MSELoss()\n",
    "                \n",
    "                loss_mse = criterion_mse(model_out, images_out[None, :, :, :])\n",
    "                loss_mae = criterion(model_out, images_out[None, :, :, :])\n",
    "                \n",
    "                mae_total.append(loss_mae.detach().cpu().numpy())\n",
    "                rmse_total.append(math.sqrt(loss_mse.detach().cpu().numpy()))\n",
    "                \n",
    "            \n",
    "            wandb.log(\n",
    "                {\n",
    "                 \"test/test_MAE\": average(mae_total), \n",
    "                 \"test/test_RMSE\": average(rmse_total)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print('Epoch ', epoch, ', test MAE - ', average(mae_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "791f51cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5443/1818241839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_gfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5443/558365689.py\u001b[0m in \u001b[0;36mtrain_gfs\u001b[0;34m(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step, normalize)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 {\n\u001b[1;32m     55\u001b[0m                  \u001b[0;34m\"test/test_MAE\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                  \u001b[0;34m\"test/test_RMSE\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 }\n\u001b[1;32m     58\u001b[0m             )\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mPreInitCallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: N802\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must call wandb.init() before {}()\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "from models.unet.unet.unet_model import UNet\n",
    "\n",
    "epochs = 1000\n",
    "d_in, d_out = 7, 3\n",
    "batch_size = 2\n",
    "lr = 1e-3\n",
    "eval_step = 20\n",
    "normalize = True\n",
    "criterion = nn.L1Loss()\n",
    "model_a = UNet(15, 3).to(device)\n",
    "\n",
    "train_gfs(model_a, criterion, d_in, d_out, epochs, batch_size, lr, eval_step, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "15b5c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images_tensor_train_gfs_np):\n",
    "    data = images_tensor_train_gfs.cpu().numpy()\n",
    "    data_min = np.min(data, axis=(1,2,3), keepdims=True)\n",
    "    data_max = np.max(data, axis=(1,2,3), keepdims=True)\n",
    "\n",
    "    scaled_data = (data - data_min) / (data_max - data_min)\n",
    "    return torch.Tensor(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1b2a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tensor_train_gfs_np = images_tensor_train_gfs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b90595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = images_tensor_train_gfs_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a3fd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data = np.random.normal(loc=0, scale=1, size=(96108, 7, 7))\n",
    "data_min = np.min(data, axis=(1,2,3), keepdims=True)\n",
    "data_max = np.max(data, axis=(1,2,3), keepdims=True)\n",
    "\n",
    "scaled_data = (data - data_min) / (data_max - data_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c589a6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1812, 9, 360, 500)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3dfe40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9777034 , 0.9773288 , 0.9768093 , ..., 0.96315116, 0.96308655,\n",
       "        0.9630696 ],\n",
       "       [0.977667  , 0.9772811 , 0.97686255, ..., 0.96296054, 0.9629497 ,\n",
       "        0.96293   ],\n",
       "       [0.9776438 , 0.97724694, 0.97685874, ..., 0.96282965, 0.9628245 ,\n",
       "        0.96276325],\n",
       "       ...,\n",
       "       [0.9847687 , 0.98451895, 0.98426574, ..., 0.92624736, 0.9258093 ,\n",
       "        0.92527354],\n",
       "       [0.98462695, 0.98437583, 0.9841222 , ..., 0.92687666, 0.92632633,\n",
       "        0.92608243],\n",
       "       [0.98448104, 0.98422205, 0.98397183, ..., 0.92726815, 0.927024  ,\n",
       "        0.9266455 ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d823cac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03487178, 0.03487178, 0.03487178, ..., 0.03487178, 0.03487178,\n",
       "        0.03487178],\n",
       "       [0.03487178, 0.03487178, 0.03487178, ..., 0.03487178, 0.03487178,\n",
       "        0.03487178],\n",
       "       [0.03487178, 0.03487178, 0.03487178, ..., 0.03487178, 0.03487178,\n",
       "        0.03487178],\n",
       "       ...,\n",
       "       [0.03487178, 0.03487178, 0.03487178, ..., 0.03487178, 0.03487178,\n",
       "        0.03487178],\n",
       "       [0.03487178, 0.03487178, 0.03487178, ..., 0.03487178, 0.03487178,\n",
       "        0.03487178],\n",
       "       [0.03487178, 0.03487178, 0.03487178, ..., 0.03487178, 0.03487178,\n",
       "        0.03487178]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34245c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[270.3709, 270.2635, 270.1146,  ..., 266.1979, 266.1794, 266.1745],\n",
       "        [270.3605, 270.2498, 270.1298,  ..., 266.1432, 266.1401, 266.1345],\n",
       "        [270.3539, 270.2401, 270.1287,  ..., 266.1057, 266.1042, 266.0866],\n",
       "        ...,\n",
       "        [272.3970, 272.3254, 272.2528,  ..., 255.6152, 255.4896, 255.3359],\n",
       "        [272.3564, 272.2844, 272.2116,  ..., 255.7956, 255.6378, 255.5679],\n",
       "        [272.3145, 272.2403, 272.1685,  ..., 255.9079, 255.8379, 255.7293]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tensor_train_gfs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8929e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1.,2.,3.],[4.,5.,6.]])\n",
    "print(\"Tensor:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "435bbe58",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5443/295978509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "t1 = normalize(t, p=1.0, dim = 1)\n",
    "t2 = normalize(t, p=2.0, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b46ad1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000e+01,  0.0000e+00,  3.1983e-05,  ...,  1.0000e+02,\n",
       "         1.0000e+02,  1.0000e+02], device='cuda:1')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(images_tensor_train_gfs[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fac4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f91143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalize_layer = torch.nn.functional.normalize(input, p=2.0, dim=1, eps=1e-12, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241b092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f7a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768dad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb59322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f123d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5197164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4652996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330d1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a175bd8c",
   "metadata": {},
   "source": [
    "### Prebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd4271aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.unet3d.unet3d.unet3d.model import UNet3D, ResidualUNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33c3fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46420d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d = UNet3D(7, 3).to(device)\n",
    "model_3d_r = ResidualUNet3D(7, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d0912eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 6, 360, 500]), torch.Size([1, 7, 10, 360, 500]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = images_tensor_train_gfs[:7][None, :, :, :, :]\n",
    "out = F.pad(init, (0, 0, 0, 0, 2, 2), \"constant\", 0)\n",
    "init.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f92b0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15d0c583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It works!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(863.4682, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model_3d(out).squeeze(), images_tensor_test[0+7:0+7+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29e7cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It works!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 360, 500])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3d(out).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "578d1bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 6, 360, 500])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(2, images_tensor_train_gfs, 7, 3)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08304b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7, 6, 360, 500]), torch.Size([3, 6, 360, 500]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tensor_test_gfs[0:0+7][None, :, :, :, :].shape, images_tensor_test_gfs[0+7:0+7+3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59746585",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_point' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2384/2383084489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_tensor_test_gfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md_in\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'start_point' is not defined"
     ]
    }
   ],
   "source": [
    "images_tensor_test_gfs[start_point+d_in:start_point+d_in+d_out].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d241a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_3d(batch_size, images_tensor, d_in, d_out):\n",
    "    in_batch, out_batch = [], []\n",
    "    for i in range(batch_size):\n",
    "        start_point = choice(range(len(images_tensor) - d_in - d_out))\n",
    "        in_batch.append(images_tensor[start_point:start_point+d_in])\n",
    "        out_batch.append(images_tensor[start_point+d_in:start_point+d_in+d_out])\n",
    "    return torch.stack(in_batch), torch.stack(out_batch)\n",
    "\n",
    "\n",
    "def train_3d(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) #weight_decay=1e-8, momentum=0.9\n",
    "#    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "#    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(\"Current epoch\", epoch)\n",
    "        model.train()\n",
    "        images_in, images_out = load_data_3d(batch_size, images_tensor_train_gfs, d_in, d_out)\n",
    "        optimizer.zero_grad()\n",
    "        images_in_padded = F.pad(images_in, (0, 0, 0, 0, 1, 1), \"constant\", 0)\n",
    "        model_out = model(images_in_padded)\n",
    "        loss = criterion(model_out, images_out[:, :, -1, :, :])\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if epoch % eval_step == 0:\n",
    "            mae_total, rmse_total, mape_total = [], [], []\n",
    "            \n",
    "            total_test_len = len(images_tensor_test_gfs)\n",
    "            start_point, steps = 0, int(total_test_len/(d_in + d_out))\n",
    "            \n",
    "            for i in tqdm(range(steps)):\n",
    "                images_in, images_out = images_tensor_test_gfs[start_point:start_point+d_in],\\\n",
    "                                        images_tensor_test_gfs[start_point+d_in:start_point+d_in+d_out][:, -1, :, :]\n",
    "                \n",
    "                start_point += d_in + d_out\n",
    "                \n",
    "                images_in_padded = F.pad(images_in, (0, 0, 0, 0, 1, 1), \"constant\", 0)\n",
    "                model_out = model(images_in_padded[None, :, :, :, :]).squeeze()\n",
    "                \n",
    "                criterion_mse = nn.MSELoss()\n",
    "                \n",
    "                loss_mse = criterion_mse(model_out, images_out[None, :, :, :])\n",
    "                loss_mae = criterion(model_out, images_out[None, :, :, :])\n",
    "                \n",
    "                mae_total.append(loss_mae.detach().cpu().numpy())\n",
    "                rmse_total.append(math.sqrt(loss_mse.detach().cpu().numpy()))\n",
    "                del images_in, images_out, model_out\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            wandb.log(\n",
    "                {\n",
    "                 \"test/test_MAE\": average(mae_total), \n",
    "                 \"test/test_RMSE\": average(rmse_total)\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print('Epoch ', epoch, ', test MAE - ', average(mae_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda7ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbercv\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-07-24 11:31:50.786818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">divine-firefly-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction/runs/1t5cu1nc\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction/runs/1t5cu1nc</a><br/>\n",
       "                Run data is saved locally in <code>/home/jovyan/Ice/wandb/run-20220724_113148-1t5cu1nc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = \"UNet3D_default\"\n",
    "i = 0\n",
    "wandb.init(project=\"SeaIcePrediction\", entity=\"eighonet\", group=architecture)\n",
    "wandb.run.name = architecture + \"_\" + str(i)  # \"gs_3_ffd_3_128_test_MAEloss_lr_10^{-4}_10000\"\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ef318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68e2e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Current epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.03 GiB (GPU 0; 31.72 GiB total capacity; 29.64 GiB already allocated; 746.44 MiB free; 29.67 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2525/1638878690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2525/2082098734.py\u001b[0m in \u001b[0;36mtrain_3d\u001b[0;34m(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimages_in_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_in_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/unet3d/unet3d/unet3d/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# pass the output from the corresponding encoder and the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# of the previous decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/unet3d/unet3d/unet3d/buildingblocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_features, x)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         return F.group_norm(\n\u001b[0;32m--> 247\u001b[0;31m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m     \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.03 GiB (GPU 0; 31.72 GiB total capacity; 29.64 GiB already allocated; 746.44 MiB free; 29.67 GiB reserved in total by PyTorch)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "ERROR:root:dropped chunk 404 Client Error: Not Found for url: https://api.wandb.ai/files/eighonet/SeaIcePrediction/1t5cu1nc/file_stream\n",
      "NoneType: None\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.unet3d.unet3d.unet3d.model import UNet3D, ResidualUNet3D\n",
    "\n",
    "epochs = 100\n",
    "d_in, d_out = 7, 3\n",
    "batch_size = 1\n",
    "lr = 1e-3\n",
    "eval_step = 10\n",
    "criterion = nn.L1Loss()\n",
    "model_3d = UNet3D(7, 3).to(device)\n",
    "\n",
    "train_3d(model_3d, criterion, d_in, d_out, epochs, batch_size, lr, eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86900bcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'UNet3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4884/3649336661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUNet3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'UNet3D' is not defined"
     ]
    }
   ],
   "source": [
    "UNet3D(7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6fd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bd4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18635da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f0ed3e",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16faebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 3\n",
    "test_conv3d = nn.Conv3d(7, 1, kernel_size=3, padding=1, bias=False).to(device)\n",
    "test_conv2d = nn.Conv2d(6, out_channels, kernel_size=3, padding=1, bias=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5be6242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 360, 500])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv3d(images_tensor_train_gfs[:7][None, :, :, :, :]).squeeze(1).shape\n",
    "result_prj = test_conv3d(images_tensor_train_gfs[:7][None, :, :, :, :]).squeeze(1)\n",
    "test_conv2d(result_prj).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d61d527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 6, 360, 500])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tensor_train_gfs[:7][None, :, :, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cce271f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 360, 500])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8fc135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f7cf947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.unet.unet.unet_model_3d import UNet_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1babf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d = UNet_3d(7, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a202a124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 90, 125])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([1, 256, 1, 90, 125]).squeeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7e4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet_3d(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv3d(7, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down_2d(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv_2d(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down_2d(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv_2d(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv_2d(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv_2d(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv_2d(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv_2d(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d00e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 3, 180, 250])\n",
      "torch.Size([1, 256, 90, 125])\n",
      "torch.Size([1, 512, 45, 62])\n",
      "torch.Size([1, 1024, 22, 31])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 4 and 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1656/3443050311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_tensor_train_gfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/unet/unet/unet_model_3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ice/models/unet/unet/unet_parts_3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 5"
     ]
    }
   ],
   "source": [
    "model_3d(images_tensor_train_gfs[:7][None, :, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf30fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fd0e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/jovyan/Ice/models/unet/unet/unet_parts_3d.py\u001b[0m(99)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     97 \u001b[0;31m        \u001b[0;31m# https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m        \u001b[0;31m# https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 99 \u001b[0;31m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    100 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> x2.shape\n",
      "torch.Size([1, 128, 3, 180, 250])\n",
      "ipdb> x1.shape\n",
      "torch.Size([1, 128, 3, 180])\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7404724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
