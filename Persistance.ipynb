{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a94e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
      "Requirement already satisfied: torch==1.8.0+cu101 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (1.8.0+cu101)\n",
      "Requirement already satisfied: torchvision==0.9.0 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (0.9.0+cu101)\n",
      "Requirement already satisfied: typing-extensions in /home/user/conda/lib/python3.7/site-packages (from torch==1.8.0+cu101) (4.0.1)\n",
      "Requirement already satisfied: numpy in /home/user/conda/lib/python3.7/site-packages (from torch==1.8.0+cu101) (1.21.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/user/conda/lib/python3.7/site-packages (from torchvision==0.9.0) (9.0.0)\n",
      "Requirement already satisfied: wandb==0.12.1 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (0.12.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (3.1.26)\n",
      "Requirement already satisfied: PyYAML in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (6.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (5.9.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (5.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (2.27.1)\n",
      "Requirement already satisfied: pathtools in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (from wandb==0.12.1) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (8.0.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (from wandb==0.12.1) (1.0.9)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (3.19.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (from wandb==0.12.1) (3.5.4)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (1.16.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (from wandb==0.12.1) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (from wandb==0.12.1) (1.8.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/jovyan/.imgenv-bert-large-0/lib/python3.7/site-packages (from wandb==0.12.1) (2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/user/conda/lib/python3.7/site-packages (from wandb==0.12.1) (2.8.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/user/conda/lib/python3.7/site-packages (from Click!=8.0.0,>=7.0->wandb==0.12.1) (4.10.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/user/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb==0.12.1) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb==0.12.1) (4.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.12.1) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.12.1) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.12.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/user/conda/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb==0.12.1) (2.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/user/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.12.1) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/conda/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb==0.12.1) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -f https://download.pytorch.org/whl/cu101/torch_stable.html torch==1.8.0+cu101 torchvision==0.9.0\n",
    "!pip install wandb==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffdd35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from random import *\n",
    "seed(0)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"сpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c4c0c",
   "metadata": {},
   "source": [
    "### Data trepanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9ead204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1812, 366, 365)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'barents'\n",
    "folder_train, folder_val, folder_test = dataset + '/train/maps/', dataset + '/valid/maps/', dataset + '/test/maps/'\n",
    "train_files, val_files, test_files = sorted([file for file in listdir(folder_train)])[1346:],\\\n",
    "                                     sorted([file for file in listdir(folder_val)]),\\\n",
    "                                     sorted([file for file in listdir(folder_test)]) # + 1200\n",
    "\n",
    "sample = torch.load(folder_train + train_files[1])\n",
    "grid = torch.load(dataset + \"/train/grid.pt\")\n",
    "coverage = pd.read_csv(dataset + \"/train/coverage.csv\")\n",
    "\n",
    "len(train_files), len(val_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "093f25ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    return (torch.nan_to_num(tensor, nan=-10.0) + grid['land']*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66108d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1812/1812 [00:15<00:00, 118.05it/s]\n",
      " 52%|█████▏    | 189/366 [00:01<00:01, 135.27it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7087/61960648.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m images_val = [preprocess_image(torch.load(folder_val + val_files[i])[\"jaxa.sic\"])\\\n\u001b[0;32m----> 5\u001b[0;31m                             for i in tqdm(range(0, len(val_files)))]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7087/61960648.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m images_val = [preprocess_image(torch.load(folder_val + val_files[i])[\"jaxa.sic\"])\\\n\u001b[0;32m----> 5\u001b[0;31m                             for i in tqdm(range(0, len(val_files)))]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-bert-large-0/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "images_train = [preprocess_image(torch.load(folder_train + train_files[i])[\"jaxa.sic\"])\\\n",
    "                            for i in tqdm(range(0, len(train_files)))]\n",
    "\n",
    "images_val = [preprocess_image(torch.load(folder_val + val_files[i])[\"jaxa.sic\"])\\\n",
    "                            for i in tqdm(range(0, len(val_files)))]\n",
    "\n",
    "def handler(data: dict):\n",
    "    try:\n",
    "        return data[\"jaxa.sic\"]\n",
    "    except:\n",
    "        return data[\"jaxa.sic_asc\"]\n",
    "    \n",
    "images_test = [preprocess_image(handler(torch.load(folder_test + test_files[i])))\\\n",
    "                            for i in tqdm(range(0, len(test_files)))]\n",
    "\n",
    "images_tensor_train, images_tensor_val, images_tensor_test = torch.stack(images_train),\\\n",
    "                                                             torch.stack(images_val),\\\n",
    "                                                             torch.stack(images_test)\n",
    "images_tensor_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c52fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data: list) -> float:\n",
    "    return sum(data)/len(data)\n",
    "\n",
    "def load_data(batch_size, images_tensor, d_in, d_out):\n",
    "    in_batch, out_batch = [], []\n",
    "    for i in range(batch_size):\n",
    "        start_point = choice(range(len(images_tensor) - d_in - d_out))\n",
    "        in_batch.append(images_tensor[start_point:start_point+d_in])\n",
    "        out_batch.append(images_tensor[start_point+d_in:start_point+d_in+d_out])\n",
    "    return torch.stack(in_batch), torch.stack(out_batch)\n",
    "\n",
    "def train(model, criterion, d_in, d_out, epochs, batch_size, lr, eval_step):\n",
    "    mae_total, rmse_total, mape_total = [], [], []\n",
    "\n",
    "    total_test_len = len(images_tensor_test)\n",
    "    start_point, steps = 0, int(total_test_len/(d_in + d_out))\n",
    "\n",
    "    for i in range(steps):\n",
    "        model_out, images_out = torch.stack([images_tensor_test[start_point+d_in] for i in range(d_out)]),\\\n",
    "                                images_tensor_test[start_point+d_in+1:start_point+d_in+d_out+1]\n",
    "\n",
    "        start_point += d_in + d_out\n",
    "\n",
    "\n",
    "        criterion_mse = nn.MSELoss()\n",
    "\n",
    "        loss_mse = criterion_mse(model_out, images_out[None, :, :, :])\n",
    "        loss_mae = criterion(model_out, images_out[None, :, :, :])\n",
    "\n",
    "        mae_total.append(loss_mae.detach().cpu().numpy())\n",
    "        rmse_total.append(math.sqrt(loss_mse.detach().cpu().numpy()))\n",
    "\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "         \"test/test_MAE\": average(mae_total), \n",
    "         \"test/test_RMSE\": average(rmse_total)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print('Epoch ', 0, ', test MAE - ', average(mae_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270a848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gz5fzbeq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7199<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jovyan/Ice/wandb/run-20220726_130644-gz5fzbeq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jovyan/Ice/wandb/run-20220726_130644-gz5fzbeq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">quiet-dew-46</strong>: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction/runs/gz5fzbeq\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction/runs/gz5fzbeq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:gz5fzbeq). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-07-26 13:09:35.731820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">different-bush-47</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/eighonet/SeaIcePrediction/runs/1u5dg6y9\" target=\"_blank\">https://wandb.ai/eighonet/SeaIcePrediction/runs/1u5dg6y9</a><br/>\n",
       "                Run data is saved locally in <code>/home/jovyan/Ice/wandb/run-20220726_130928-1u5dg6y9</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = \"Persistance_7:1\"\n",
    "i = 0\n",
    "wandb.init(project=\"SeaIcePrediction\", entity=\"eighonet\", group=architecture)\n",
    "wandb.run.name = architecture + \"_\" + str(i)  # \"gs_3_ffd_3_128_test_MAEloss_lr_10^{-4}_10000\"\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97c45d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 , test MAE -  2.496330492424242\n"
     ]
    }
   ],
   "source": [
    "epochs = 1500\n",
    "d_in, d_out = 1,10 \n",
    "batch_size = 8\n",
    "lr = 1e-3\n",
    "eval_step = 20\n",
    "criterion = nn.L1Loss()\n",
    "model_a = []\n",
    "\n",
    "train(model_a, criterion, d_in, d_out, epochs, batch_size, lr, eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0efa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43297a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76065190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074c8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e33b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "#model = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fff9d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(7, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-2])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb09c277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_input = torch.zeros(4, 7, 360, 500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec44a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843a485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b0a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38783d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024, 24, 32])\n",
      "torch.Size([4, 512, 72, 96])\n",
      "torch.Size([4, 511, 72, 96])\n",
      "torch.Size([4, 3, 360, 500])\n"
     ]
    }
   ],
   "source": [
    "conv_int1 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1, bias=False).to(device)\n",
    "conv_int2 = nn.Conv2d(512, 511, kernel_size=3, padding=1, bias=False).to(device)\n",
    "\n",
    "up1 = nn.ConvTranspose2d(2048, 2048 // 2, kernel_size=2, stride=(2,2)).to(device)\n",
    "up2 = nn.ConvTranspose2d(1024, 1024 // 2, kernel_size=3, stride=(3,3)).to(device)\n",
    "up3 = nn.ConvTranspose2d(511, 511 // 170, kernel_size=(5, 25), stride=(5,5)).to(device)\n",
    "#up4 = nn.ConvTranspose2d(3, 3, kernel_size=(1,21), stride=(1,1)).to(device)\n",
    "\n",
    "#print(resnet152_aug(test_input).shape)\n",
    "print(conv_int1(up1(model(test_input))).shape)\n",
    "print(up2(up1(model(test_input))).shape)\n",
    "print(conv_int2(up2(up1(model(test_input)))).shape)\n",
    "print(up3(conv_int2(up2(up1(model(test_input))))).shape)\n",
    "#print(up4(up3(conv_int2(up2(up1(model(test_input)))))).shape)\n",
    "#print(up5(up4(up3(up2(up1(model(test_input)))))).shape)\n",
    "#print(up6(up5(up4(up3(up2(up1(model(test_input))))))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0573b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5af48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33a392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1878877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2884597",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_aug = nn.Sequential(\n",
    "    model,\n",
    "    nn.ConvTranspose2d(2048, 2048 // 2, kernel_size=2, stride=(2,2)),\n",
    "    nn.Conv2d(1024, 1024, kernel_size=3, padding=1, bias=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.ConvTranspose2d(1024, 1024 // 2, kernel_size=3, stride=(3,3)),\n",
    "    nn.Conv2d(512, 511, kernel_size=3, padding=1, bias=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.ConvTranspose2d(511, 511 // 511, kernel_size=(5, 25), stride=(5,5)).to(device)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54ffb79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 360, 500])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet152_aug(test_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe77c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  20 , test MAE -  9.794620090060764\n",
      "Epoch  40 , test MAE -  9.406392415364584\n",
      "Epoch  60 , test MAE -  8.692482503255208\n",
      "Epoch  80 , test MAE -  8.557862006293403\n",
      "Epoch  100 , test MAE -  8.664781358506945\n",
      "Epoch  120 , test MAE -  8.152642822265625\n",
      "Epoch  140 , test MAE -  8.534897189670138\n",
      "Epoch  160 , test MAE -  7.208463541666666\n",
      "Epoch  180 , test MAE -  6.957613796657986\n",
      "Epoch  200 , test MAE -  6.357668050130209\n",
      "Epoch  220 , test MAE -  5.774461534288195\n",
      "Epoch  240 , test MAE -  6.263149007161458\n",
      "Epoch  260 , test MAE -  6.740200466579861\n",
      "Epoch  280 , test MAE -  5.680073377821181\n",
      "Epoch  300 , test MAE -  5.202086724175347\n",
      "Epoch  320 , test MAE -  5.172831556532118\n",
      "Epoch  340 , test MAE -  5.284344482421875\n",
      "Epoch  360 , test MAE -  5.218190171983507\n",
      "Epoch  380 , test MAE -  4.885006374782986\n",
      "Epoch  400 , test MAE -  5.458393351236979\n",
      "Epoch  420 , test MAE -  4.994831339518229\n",
      "Epoch  440 , test MAE -  4.921678331163195\n",
      "Epoch  460 , test MAE -  5.898794216579861\n",
      "Epoch  480 , test MAE -  5.658295016818577\n",
      "Epoch  500 , test MAE -  5.623846774631076\n",
      "Epoch  520 , test MAE -  5.592432318793403\n",
      "Epoch  540 , test MAE -  5.595101589626736\n",
      "Epoch  560 , test MAE -  4.869226752387153\n",
      "Epoch  580 , test MAE -  4.971918063693576\n",
      "Epoch  600 , test MAE -  5.572669813368056\n",
      "Epoch  620 , test MAE -  5.127943250868055\n",
      "Epoch  640 , test MAE -  4.899659220377604\n",
      "Epoch  660 , test MAE -  5.18110114203559\n",
      "Epoch  680 , test MAE -  5.1083526611328125\n",
      "Epoch  700 , test MAE -  4.65746595594618\n",
      "Epoch  720 , test MAE -  5.049141438802083\n",
      "Epoch  740 , test MAE -  4.683679538302951\n",
      "Epoch  760 , test MAE -  4.383071560329861\n",
      "Epoch  780 , test MAE -  4.504765150282118\n",
      "Epoch  800 , test MAE -  4.129442681206597\n",
      "Epoch  820 , test MAE -  4.3157640245225695\n",
      "Epoch  840 , test MAE -  4.060721842447917\n",
      "Epoch  860 , test MAE -  4.32291497124566\n",
      "Epoch  880 , test MAE -  4.698226250542534\n",
      "Epoch  900 , test MAE -  4.545648871527778\n",
      "Epoch  920 , test MAE -  3.9309319390190973\n",
      "Epoch  940 , test MAE -  4.274550035264757\n",
      "Epoch  960 , test MAE -  3.847827826605903\n",
      "Epoch  980 , test MAE -  5.876389567057291\n",
      "Epoch  1000 , test MAE -  4.224107191297743\n",
      "Epoch  1020 , test MAE -  4.257737562391493\n",
      "Epoch  1040 , test MAE -  3.832266574435764\n",
      "Epoch  1060 , test MAE -  3.7397508409288194\n",
      "Epoch  1080 , test MAE -  4.075304836697049\n",
      "Epoch  1100 , test MAE -  3.85469970703125\n",
      "Epoch  1120 , test MAE -  3.7560719807942706\n",
      "Epoch  1140 , test MAE -  3.6940338134765627\n",
      "Epoch  1160 , test MAE -  3.8186279296875\n",
      "Epoch  1180 , test MAE -  3.6379692925347222\n",
      "Epoch  1200 , test MAE -  3.713445027669271\n",
      "Epoch  1220 , test MAE -  3.570873006184896\n",
      "Epoch  1240 , test MAE -  3.6436614990234375\n",
      "Epoch  1260 , test MAE -  3.575381808810764\n",
      "Epoch  1280 , test MAE -  3.5102220323350695\n"
     ]
    }
   ],
   "source": [
    "from models.unet.unet.unet_model import UNet\n",
    "\n",
    "epochs = 1500\n",
    "d_in, d_out = 7, 1\n",
    "batch_size = 8\n",
    "lr = 1e-3\n",
    "eval_step = 20\n",
    "criterion = nn.L1Loss()\n",
    "model_a = resnet152_aug.to(device)\n",
    "\n",
    "train(resnet152_aug, criterion, d_in, d_out, epochs, batch_size, lr, eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0041c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet152_aug, criterion, d_in, d_out, 10000, 16, 1e-4, eval_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358827c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
